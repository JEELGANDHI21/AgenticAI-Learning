{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69977c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12812086",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import ChatOpenAI\n",
    "from openai import OpenAI\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0127bf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_t_with_space(list_of_documents):\n",
    "    \"\"\"\n",
    "    Replaces all tab characters ('\\t') with spaces in the page content of each document\n",
    "\n",
    "    Args:\n",
    "        list_of_documents: A list of document objects, each with a 'page_content' attribute.\n",
    "\n",
    "    Returns:\n",
    "        The modified list of documents with tab characters replaced by spaces.\n",
    "    \"\"\"\n",
    "\n",
    "    for doc in list_of_documents:\n",
    "        doc.page_content = doc.page_content.replace('\\t', ' ')  # Replace tabs with spaces\n",
    "    return list_of_documents\n",
    "\n",
    "def encode_pdf(file_path, chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"\n",
    "    Encodes a PDF book into a vector store using OpenAI embeddings.\n",
    "\n",
    "    Args:\n",
    "        path: The path to the PDF file.\n",
    "        chunk_size: The desired size of each text chunk.\n",
    "        chunk_overlap: The amount of overlap between consecutive chunks.\n",
    "\n",
    "    Returns:\n",
    "        A FAISS vector store containing the encoded book content.\n",
    "    \"\"\"\n",
    "    \n",
    "    loader = PyPDFLoader(file_path)\n",
    "    documents = loader.load()\n",
    "\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "    )\n",
    "\n",
    "    chunks = splitter.split_documents(documents)\n",
    "    cleaned_texts = replace_t_with_space(chunks)\n",
    "\n",
    "    embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "    vectorstore = FAISS.from_documents(cleaned_texts, embeddings)\n",
    "\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd56d765",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyDERetriever:\n",
    "    def __init__(self, file_path, chunk_size = 1000, chunk_overlap = 200):\n",
    "        self.llm = ChatOpenAI(temperature=0, model=\"meta-llama/llama-3.3-70b-instruct\", max_tokens=4000)\n",
    "        \n",
    "        self.embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "        self.chunk_size = chunk_size\n",
    "        self.chunk_overlap = chunk_overlap\n",
    "        self.vectorstore = encode_pdf(file_path, chunk_size, chunk_overlap)\n",
    "        \n",
    "        self.hyde_prompt = PromptTemplate(\n",
    "            input_variables=[\"query\"],\n",
    "            template=\"\"\"\n",
    "                You are summarizing how a 400-page AI engineering textbook explains a concept.\n",
    "\n",
    "                Based on the question below, write a synthetic passage that reflects\n",
    "                how the book would discuss this topic across multiple chapters.\n",
    "\n",
    "                Focus on:\n",
    "                - practical framing\n",
    "                - systems and agents\n",
    "                - engineering perspective\n",
    "                - how the concept is used, not just defined\n",
    "\n",
    "                Question:\n",
    "                {query}\n",
    "                \"\"\"\n",
    "            )\n",
    "        \n",
    "        self.hyde_chain = self.hyde_prompt | self.llm\n",
    "        \n",
    "    def generate_hypothetical_document(self, query):\n",
    "        input_variables = {\"query\": query, \"chunk_size\": self.chunk_size}\n",
    "        return self.hyde_chain.invoke(input_variables).content\n",
    "        \n",
    "    def retrieve(self, query, k=8):\n",
    "        hypothetical_doc = self.generate_hypothetical_document(query)\n",
    "        similar_docs = self.vectorstore.similarity_search(hypothetical_doc, k=k)\n",
    "        return similar_docs, hypothetical_doc\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d4d79b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"AI_Engineer_Book.pdf\"\n",
    "\n",
    "retriever = HyDERetriever(path, chunk_size=500, chunk_overlap=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63e1b659",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query = \"What is LLM?\"\n",
    "results, hypothetical_doc = retriever.retrieve(test_query, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83c390eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "def text_wrap(text, width=120):\n",
    "    \"\"\"\n",
    "    Wraps the input text to the specified width.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text to wrap.\n",
    "        width (int): The width at which to wrap the text.\n",
    "\n",
    "    Returns:\n",
    "        str: The wrapped text.\n",
    "    \"\"\"\n",
    "    return textwrap.fill(text, width=width)\n",
    "\n",
    "def show_context(context):\n",
    "    \"\"\"\n",
    "    Display the contents of the provided context list.\n",
    "\n",
    "    Args:\n",
    "        context (list): A list of context items to be displayed.\n",
    "\n",
    "    Prints each context item in the list with a heading indicating its position.\n",
    "    \"\"\"\n",
    "    for i, c in enumerate(context):\n",
    "        print(f\"Context {i + 1}:\")\n",
    "        print(c)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c17eed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hypothetical_doc:\n",
      "\n",
      "Large Language Models (LLMs) are a class of artificial intelligence (AI) systems that have revolutionized the field of\n",
      "natural language processing (NLP). From an engineering perspective, LLMs can be viewed as complex software systems that\n",
      "leverage deep learning techniques to process and generate human-like language. These models are designed to learn\n",
      "patterns and relationships within vast amounts of text data, enabling them to perform a wide range of tasks, such as\n",
      "language translation, text summarization, and conversation generation.  In the context of systems and agents, LLMs can\n",
      "be seen as autonomous agents that interact with their environment through text-based interfaces. They receive input in\n",
      "the form of text, process it, and generate output that is often indistinguishable from human-generated text. This\n",
      "interaction can be viewed as a feedback loop, where the LLM adapts to the user's input and adjusts its output\n",
      "accordingly. For instance, in a conversational AI system, the LLM agent receives user input, processes it, and responds\n",
      "with a generated text that is contextually relevant.  From a practical perspective, LLMs have numerous applications in\n",
      "areas such as customer service, content generation, and language translation. They can be used to power chatbots,\n",
      "virtual assistants, and other conversational interfaces, enabling businesses to automate tasks, improve customer\n",
      "engagement, and reduce operational costs. Moreover, LLMs can be fine-tuned for specific domains, such as medical or\n",
      "financial text analysis, to extract insights and generate reports.  The engineering of LLMs involves a range of\n",
      "techniques, including data preprocessing, model architecture design, and training algorithms. The choice of model\n",
      "architecture, such as transformer-based or recurrent neural network-based, depends on the specific application and the\n",
      "characteristics of the input data. Additionally, the training process involves optimizing the model's parameters to\n",
      "minimize the difference between the predicted output and the actual output, using techniques such as masked language\n",
      "modeling and next sentence prediction.  In terms of system design, LLMs can be integrated with other AI systems, such as\n",
      "computer vision and speech recognition, to create multimodal interfaces that can interact with users through multiple\n",
      "channels. For example, a virtual assistant can use LLMs to generate text responses, while also using computer vision to\n",
      "recognize objects and speech recognition to understand voice commands. This integration enables the creation of more\n",
      "sophisticated and human-like interfaces that can interact with users in a more natural and intuitive way.  Overall, LLMs\n",
      "are a powerful tool for NLP tasks, and their applications continue to expand as the field of AI advances. By\n",
      "understanding the engineering principles and system design considerations behind LLMs, developers can create more\n",
      "effective and efficient language-based interfaces that can interact with users in a more human-like way.\n",
      "\n",
      "Context 1:\n",
      "DailyDoseofDS.com \n",
      "How to make the most out of \n",
      "this book and your time? The reading time of this book is about 20 hours. But not all chapters will be of \n",
      "relevance to you. This 2-minute assessment will test your current expertise and \n",
      "recommend chapters that will be most useful to you. \n",
      " \n",
      "Scan the QR code below or open this link to start the assessment. It will only take \n",
      "2 minutes to complete. \n",
      " \n",
      " \n",
      "https://bit.ly/ai-engg-assessment \n",
      "1\n",
      "\n",
      "\n",
      "Context 2:\n",
      "DailyDoseofDS.com \n",
      " \n",
      " \n",
      " \n",
      "AI Engineering \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "2\n",
      "\n",
      "\n",
      "Context 3:\n",
      "FREE\n",
      "AI Engineering\n",
      "2025 EDITION\n",
      "Akshay Pachaar & Avi Chawla\n",
      "DailyDoseofDS.com\n",
      "Daily Dose of\n",
      "Data Science\n",
      "System Design Patterns for\n",
      "LLMs, RAG and Agents\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "docs_content = [doc.page_content for doc in results]\n",
    "\n",
    "# Display hypothetical document\n",
    "print(\"hypothetical_doc:\\n\")\n",
    "print(text_wrap(hypothetical_doc))\n",
    "print()\n",
    "\n",
    "# Display retrieved contexts\n",
    "show_context(docs_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-techniques",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
