{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e25ced5b",
   "metadata": {},
   "source": [
    "# HyDE RAG Technique - Hypothetical Document Embeddings\n",
    "\n",
    "## üìã Overview\n",
    "\n",
    "This implementation demonstrates the **HyDE (Hypothetical Document Embeddings)** retrieval technique, an advanced RAG (Retrieval-Augmented Generation) method that improves document retrieval by generating hypothetical answers before searching.\n",
    "\n",
    "## üéØ What is HyDE?\n",
    "\n",
    "HyDE is a retrieval technique that addresses a common problem in traditional RAG systems: **the semantic gap between user queries and document content**.\n",
    "\n",
    "### Traditional RAG Problem\n",
    "- User queries are often short and question-like\n",
    "- Documents contain detailed, declarative content\n",
    "- Direct similarity search may miss relevant documents\n",
    "\n",
    "### HyDE Solution\n",
    "1. **Generate** a hypothetical answer to the user's query using an LLM\n",
    "2. **Embed** this hypothetical document\n",
    "3. **Search** for similar documents using the hypothetical document's embedding\n",
    "4. **Retrieve** the most relevant actual documents\n",
    "\n",
    "## üèóÔ∏è Architecture\n",
    "\n",
    "```\n",
    "User Query ‚Üí LLM (Generate Hypothetical Doc) ‚Üí Embed ‚Üí Vector Search ‚Üí Retrieve Documents\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b217b367",
   "metadata": {},
   "source": [
    "**Flow**:\n",
    "1. User asks: \"What is LLM?\"\n",
    "2. LLM generates a hypothetical answer as if from the textbook\n",
    "3. Hypothetical answer is embedded\n",
    "4. Vector search finds actual textbook chunks similar to the hypothetical answer\n",
    "5. Returns top `k` most relevant chunks\n",
    "\n",
    "## üí° Why HyDE Works Better\n",
    "\n",
    "### Traditional RAG\n",
    "```\n",
    "Query: \"What is LLM?\"\n",
    "‚Üì\n",
    "Embed: [0.1, 0.3, 0.2, ...]\n",
    "‚Üì\n",
    "Search: Finds chunks with similar embeddings\n",
    "```\n",
    "\n",
    "### HyDE RAG\n",
    "```\n",
    "Query: \"What is LLM?\"\n",
    "‚Üì\n",
    "Generate: \"A Large Language Model (LLM) is a type of neural network...\"\n",
    "‚Üì\n",
    "Embed: [0.2, 0.4, 0.3, ...]  (richer semantic representation)\n",
    "‚Üì\n",
    "Search: Finds chunks similar to a full answer\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "69977c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "12812086",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import ChatOpenAI\n",
    "from openai import OpenAI\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0127bf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_t_with_space(list_of_documents):\n",
    "    \"\"\"\n",
    "    Replaces all tab characters ('\\t') with spaces in the page content of each document\n",
    "\n",
    "    Args:\n",
    "        list_of_documents: A list of document objects, each with a 'page_content' attribute.\n",
    "\n",
    "    Returns:\n",
    "        The modified list of documents with tab characters replaced by spaces.\n",
    "    \"\"\"\n",
    "\n",
    "    for doc in list_of_documents:\n",
    "        doc.page_content = doc.page_content.replace('\\t', ' ')  # Replace tabs with spaces\n",
    "    return list_of_documents\n",
    "\n",
    "def encode_pdf(file_path, chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"\n",
    "    Encodes a PDF book into a vector store using OpenAI embeddings.\n",
    "\n",
    "    Args:\n",
    "        path: The path to the PDF file.\n",
    "        chunk_size: The desired size of each text chunk.\n",
    "        chunk_overlap: The amount of overlap between consecutive chunks.\n",
    "\n",
    "    Returns:\n",
    "        A FAISS vector store containing the encoded book content.\n",
    "    \"\"\"\n",
    "    \n",
    "    loader = PyPDFLoader(file_path)\n",
    "    documents = loader.load()\n",
    "\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "    )\n",
    "\n",
    "    chunks = splitter.split_documents(documents)\n",
    "    cleaned_texts = replace_t_with_space(chunks)\n",
    "\n",
    "    embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "    vectorstore = FAISS.from_documents(cleaned_texts, embeddings)\n",
    "\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cd56d765",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyDERetriever:\n",
    "    def __init__(self, file_path, chunk_size = 1000, chunk_overlap = 200):\n",
    "        self.llm = ChatOpenAI(temperature=0, model=\"meta-llama/llama-3.3-70b-instruct\", max_tokens=4000)\n",
    "        \n",
    "        self.embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "        self.chunk_size = chunk_size\n",
    "        self.chunk_overlap = chunk_overlap\n",
    "        self.vectorstore = encode_pdf(file_path, chunk_size, chunk_overlap)\n",
    "        \n",
    "        self.hyde_prompt = PromptTemplate(\n",
    "            input_variables=[\"query\"],\n",
    "            template=\"\"\"\n",
    "                You are summarizing how a 400-page AI engineering textbook explains a concept.\n",
    "\n",
    "                Based on the question below, write a synthetic passage that reflects\n",
    "                how the book would discuss this topic across multiple chapters.\n",
    "\n",
    "                Focus on:\n",
    "                - practical framing\n",
    "                - systems and agents\n",
    "                - engineering perspective\n",
    "                - how the concept is used, not just defined\n",
    "\n",
    "                Question:\n",
    "                {query}\n",
    "                \"\"\"\n",
    "            )\n",
    "        \n",
    "        self.hyde_chain = self.hyde_prompt | self.llm\n",
    "        \n",
    "    def generate_hypothetical_document(self, query):\n",
    "        input_variables = {\"query\": query, \"chunk_size\": self.chunk_size}\n",
    "        return self.hyde_chain.invoke(input_variables).content\n",
    "        \n",
    "    def retrieve(self, query, k=8):\n",
    "        hypothetical_doc = self.generate_hypothetical_document(query)\n",
    "        similar_docs = self.vectorstore.similarity_search(hypothetical_doc, k=k)\n",
    "        return similar_docs, hypothetical_doc\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6d4d79b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"AI_Engineer_Book.pdf\"\n",
    "\n",
    "retriever = HyDERetriever(path, chunk_size=500, chunk_overlap=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "63e1b659",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query = \"What is LLM?\"\n",
    "results, hypothetical_doc = retriever.retrieve(test_query, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "83c390eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "def text_wrap(text, width=120):\n",
    "    \"\"\"\n",
    "    Wraps the input text to the specified width.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text to wrap.\n",
    "        width (int): The width at which to wrap the text.\n",
    "\n",
    "    Returns:\n",
    "        str: The wrapped text.\n",
    "    \"\"\"\n",
    "    return textwrap.fill(text, width=width)\n",
    "\n",
    "def show_context(context):\n",
    "    \"\"\"\n",
    "    Display the contents of the provided context list.\n",
    "\n",
    "    Args:\n",
    "        context (list): A list of context items to be displayed.\n",
    "\n",
    "    Prints each context item in the list with a heading indicating its position.\n",
    "    \"\"\"\n",
    "    for i, c in enumerate(context):\n",
    "        print(f\"Context {i + 1}:\")\n",
    "        print(c)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8c17eed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hypothetical_doc:\n",
      "\n",
      "Large Language Models (LLMs) are a class of artificial intelligence (AI) systems that have revolutionized the field of\n",
      "natural language processing (NLP). From an engineering perspective, LLMs are complex software systems that leverage deep\n",
      "learning techniques to process and generate human-like language. These models are designed to learn patterns and\n",
      "relationships within vast amounts of text data, enabling them to perform a wide range of tasks, such as language\n",
      "translation, text summarization, and conversation generation.  In the context of systems and agents, LLMs can be viewed\n",
      "as autonomous agents that interact with their environment through text-based interfaces. These agents are capable of\n",
      "perceiving their environment, processing the input, and generating responses that are contextually relevant. For\n",
      "instance, a chatbot powered by an LLM can engage in conversation with a user, understanding their queries, and\n",
      "responding with accurate and informative answers.  From a practical framing perspective, LLMs have numerous applications\n",
      "in real-world scenarios. For example, they can be used to develop virtual assistants, such as Siri or Alexa, that can\n",
      "understand voice commands and respond accordingly. LLMs can also be employed in language translation systems, enabling\n",
      "users to communicate across linguistic and cultural boundaries. Furthermore, these models can be used to generate text\n",
      "summaries of large documents, facilitating information retrieval and knowledge discovery.  In terms of engineering,\n",
      "designing and deploying LLMs requires a multidisciplinary approach, involving expertise in machine learning, software\n",
      "engineering, and linguistics. The development of LLMs involves several key steps, including data collection, model\n",
      "training, and evaluation. The data collection process involves gathering large amounts of text data, which is then used\n",
      "to train the model using deep learning algorithms. The trained model is then evaluated on its performance using various\n",
      "metrics, such as perplexity and accuracy.  The use of LLMs also raises important considerations regarding system design,\n",
      "scalability, and reliability. As LLMs are typically trained on large amounts of data, they require significant\n",
      "computational resources and infrastructure to operate efficiently. Moreover, the complexity of these models can make\n",
      "them prone to errors and biases, which must be carefully mitigated through rigorous testing and evaluation.  In the\n",
      "broader context of AI engineering, LLMs represent a significant advancement in the field, enabling the development of\n",
      "more sophisticated and human-like AI systems. As researchers and practitioners continue to push the boundaries of LLMs,\n",
      "we can expect to see even more innovative applications of these models in areas such as human-computer interaction,\n",
      "natural language understanding, and cognitive computing. Ultimately, the development and deployment of LLMs require a\n",
      "deep understanding of the complex interplay between systems, agents, and their environment, as well as a commitment to\n",
      "responsible and ethical AI engineering practices.\n",
      "\n",
      "Context 1:\n",
      "DailyDoseofDS.com \n",
      "How to make the most out of \n",
      "this book and your time? The reading time of this book is about 20 hours. But not all chapters will be of \n",
      "relevance to you. This 2-minute assessment will test your current expertise and \n",
      "recommend chapters that will be most useful to you. \n",
      " \n",
      "Scan the QR code below or open this link to start the assessment. It will only take \n",
      "2 minutes to complete. \n",
      " \n",
      " \n",
      "https://bit.ly/ai-engg-assessment \n",
      "1\n",
      "\n",
      "\n",
      "Context 2:\n",
      "DailyDoseofDS.com \n",
      " \n",
      " \n",
      " \n",
      "AI Engineering \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "2\n",
      "\n",
      "\n",
      "Context 3:\n",
      "FREE\n",
      "AI Engineering\n",
      "2025 EDITION\n",
      "Akshay Pachaar & Avi Chawla\n",
      "DailyDoseofDS.com\n",
      "Daily Dose of\n",
      "Data Science\n",
      "System Design Patterns for\n",
      "LLMs, RAG and Agents\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "docs_content = [doc.page_content for doc in results]\n",
    "\n",
    "# Display hypothetical document\n",
    "print(\"hypothetical_doc:\\n\")\n",
    "print(text_wrap(hypothetical_doc))\n",
    "print()\n",
    "\n",
    "# Display retrieved contexts\n",
    "show_context(docs_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-techniques",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
